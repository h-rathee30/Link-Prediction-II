{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinkPredictionII.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoORGl9KFrbjrBk4qaHBHD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h-rathee30/Link-Prediction-II/blob/master/LinkPredictionII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDqDksAowiJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from google.colab import files\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQDE3gz-QCdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7v-A7ZN2Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if the data is in a .txt file\n",
        "data = pd.read_csv('Celegans.txt',delim_whitespace=True, names=('SRC', 'TGT', 'IGNORE') )\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5US0yAwdN6Ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data editiing with respect to the data uploaded \n",
        "data.drop(['IGNORE'], axis = 1, inplace = True)\n",
        "data.reset_index(drop = True, inplace = True)\n",
        "data = data.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ko5EfK_gHvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if the data provided is in gml format\n",
        "g = nx.read_gml('dolphins.gml')\n",
        "G = nx.convert_node_labels_to_integers(g, first_label=1, ordering='default')\n",
        "nx.draw(G,with_labels=True, font_weight='bold')\n",
        "data = list(G.edges)\n",
        "data = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKOKv3AqgCkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Pair_Of_Nodes(g):\n",
        "    nodes = list(g.nodes) \n",
        "    pair_of_nodes = []\n",
        "    for i in range(0, len(nodes)):\n",
        "        for j in range(i+1, len(nodes)) :\n",
        "            pair = [nodes[i], nodes[j]]\n",
        "            pair_of_nodes.append(pair)\n",
        "    return pair_of_nodes\n",
        "\n",
        "def MatrixForestIndex(g,node_pairs):\n",
        "  L = nx.laplacian_matrix(g)\n",
        "  L = L.todense()\n",
        "  n = L.shape[0]\n",
        "  I = np.identity(n)\n",
        "  S = I + L\n",
        "  S = np.linalg.inv(S)\n",
        "  Matrix_Forest_Index = []\n",
        "  for row in node_pairs:\n",
        "    node1 = row[0]\n",
        "    node2 = row[1]\n",
        "\n",
        "    temp = [ node1, node2, S[node1-1,node2-1]]\n",
        "    Matrix_Forest_Index.append(temp)\n",
        "  return Matrix_Forest_Index\n",
        "\n",
        "def Common_Neighbours_List(g, pair_of_nodes):\n",
        "    common_neighbours = []\n",
        "    for node1, node2 in pair_of_nodes:\n",
        "        length = len(list((nx.common_neighbors(g,node1,node2))))\n",
        "        temp = [node1, node2, length ]\n",
        "        common_neighbours.append(temp) \n",
        "    return common_neighbours\n",
        "\n",
        "#alpha beta are parameters\n",
        "def LHN2_Index( graph, pair_of_nodes, beta, alpha):\n",
        "  LHN2_Index = []\n",
        "  cnt = 1\n",
        "  for node1, node2 in pair_of_nodes:\n",
        "    print(cnt)\n",
        "    paths = nx.all_simple_paths(graph, source = node1, target = node2, cutoff = 4)\n",
        "    path_lengths = [len(path) for path in paths];          #this array stores the path-length with (i+1) path length, i is index\n",
        "    path_lengths.sort();\n",
        "    freq = {}                                              #this is a dictionary that stores path-length: number of paths\n",
        "    for item in path_lengths: \n",
        "      if (item in freq): \n",
        "        freq[item] += 1\n",
        "      else: \n",
        "        freq[item] = 1\n",
        "    value = 1;\n",
        "    for pathlength, num_of_path in freq.items():\n",
        "      value += (beta**pathlength) * num_of_path\n",
        "    value = alpha*value    \n",
        "    temp = [node1, node2, value]\n",
        "    LHN2_Index.append(temp)\n",
        "    cnt += 1\n",
        "  return LHN2_Index\n",
        "\n",
        "def getDictionaryFromList(input_list) :\n",
        "    dic = {}\n",
        "    for ele in input_list :\n",
        "        dic[str(ele[0])+\" \"+str(ele[1])] = ele[2]\n",
        "    return dic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VySsEgK-lvCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#spliting here to see the predictions made just by the three measaures used \n",
        "train = data\n",
        "train = train.values.tolist()\n",
        "\n",
        "tra = []\n",
        "\n",
        "for dt in range(0,len(train)) :\n",
        "    node1 = train[dt][0] if train[dt][0] < train[dt][1] else train[dt][1]  \n",
        "    node2 = train[dt][0] if train[dt][0] > train[dt][1] else train[dt][1]\n",
        "    if node1 == node2 : continue\n",
        "    else : tra.append([node1, node2])  \n",
        "\n",
        "train = tra    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhpn024l_qOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build a graph which contains edges just in the training data set\n",
        "No_of_nodes = data.to_numpy()\n",
        "No_of_nodes = np.unique(No_of_nodes)\n",
        "nodes_input = np.sort(No_of_nodes)\n",
        "\n",
        "graph = nx.Graph()\n",
        "for i in nodes_input: \n",
        "    graph.add_node(i)\n",
        "\n",
        "for dt in range(0,len(train)):\n",
        "    graph.add_edge(train[dt][0],train[dt][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KVutZxwI7FK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# graph visualization \n",
        "nx.draw(graph,with_labels=True, font_weight='bold', )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJbaGsph_3wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_pairs_of_nodes = Pair_Of_Nodes(graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlnMgUyuAIke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the measures for every node pair\n",
        "C_N = Common_Neighbours_List(graph,all_pairs_of_nodes)\n",
        "C_N = getDictionaryFromList(C_N)\n",
        "M_F_Index = MatrixForestIndex(graph,all_pairs_of_nodes)\n",
        "M_F_Index = getDictionaryFromList(M_F_Index)\n",
        "LHNII = LHN2_Index(graph,all_pairs_of_nodes, 0.98, 1)\n",
        "LHNII = getDictionaryFromList(LHNII)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQyR4PqqXAht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A dictionary of all the features created above\n",
        "measures = [C_N, M_F_Index, LHNII]\n",
        "feature_names = [\"Common_Neighbours\", \"Matrix_Forest_Index\", \" LHN-II\"]\n",
        "feature_table = {}\n",
        "for node1, node2 in all_pairs_of_nodes :\n",
        "    arr = [node1, node2]\n",
        "    for j in range(len(feature_names)):\n",
        "      arr.append(measures[j][str(node1)+\" \"+str(node2)]) \n",
        "    if graph.has_edge(node1, node2):\n",
        "      arr.append(1)\n",
        "    else: arr.append(0)\n",
        "    feature_table[str(node1)+\" \"+str(node2)] = arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdDgsdbibSS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_dataframe = pd.DataFrame.from_dict(feature_table, orient = 'index', columns = [\"Node1\", \"Node2\", \"Common_Neighbours\", \"Matrix_Forest_Index\", \"LHN-II\", \"Category\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6QSGfQDVCch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_dataframe.sort_values(by = 'Category', inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9XHEZ1CcCjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_KIWl2I4i3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Graphs are usually sparse so we take equal numbers of both category tuples from feature table dataset\n",
        "cat1_features = pd.DataFrame\n",
        "cnt = 0\n",
        "while features_dataframe.iloc[cnt][-1] == 0:\n",
        "  cnt+= 1\n",
        "print(cnt)\n",
        "cat1_features = features_dataframe.iloc[cnt:54946]\n",
        "cat0_features = features_dataframe.iloc[0:len(cat1_features)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC8AcjittC01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data creation i.e, train and test data and normalization\n",
        "E = cat1_features.append(cat0_features)\n",
        "X = E.copy()\n",
        "Y = E[\"Category\"].copy()\n",
        "X.drop([\"Node1\",\"Node2\", \"Category\"], axis = 1, inplace=True)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, stratify = Y )\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyhaxi2IW1Sz",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZYoovfWUDG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_reg = LogisticRegression( )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb7uY6S9PYZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_reg_param = {'penalty' : ['l1', 'l2'], 'C' : [0.1, 0.5, 1, 2, 5, 6, 7, 8, 10], 'solver' : ['liblinear', 'saga']}\n",
        "LR1_reg_grid = GridSearchCV(estimator= std_reg, param_grid= std_reg_param, scoring = 'accuracy', cv = 10, return_train_score=True, verbose=True )\n",
        "LR1_reg_grid_fit = LR1_reg_grid.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCwtvECCYCzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_results_reg= pd.DataFrame.from_dict(LR1_reg_grid_fit.cv_results_)\n",
        "cv_results_reg.sort_values(by= 'rank_test_score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7hXPrz0avLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR1 = LogisticRegression(C= 6, solver= 'saga', penalty= 'l1')\n",
        "LR1.fit(x_train,y_train)\n",
        "y_pred = LR1.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPoCW2ixYJcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cofusion matrix\n",
        "LR1_confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "LR1_confusion_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2dk5r0m7nVT",
        "colab_type": "text"
      },
      "source": [
        "# **XGBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX_8XUMSZV5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb = XGBClassifier( )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95lEzHWS8qZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb_param = {'learning_rate' : [0.01, 0.05, 0.1, 0.2, 0.5], \n",
        "             'max_depth' : [ 6, 8, 10], \n",
        "             'objective' : ['binary:logistic', 'reg:logistic'], \n",
        "             'subsample' : [0.5, 0.7], \n",
        "             'gamma' : [0, 0.5, 1, 5]  }\n",
        "\n",
        "xgb_grid = GridSearchCV(estimator= xgb, param_grid= xgb_param, scoring = 'accuracy', cv = 5, return_train_score=True, verbose=True, )\n",
        "xgb_grid_fit = xgb_grid.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw-vazZqPa1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XGB_cv_results_reg= pd.DataFrame.from_dict(xgb_grid_fit.cv_results_)\n",
        "XGB_cv_results_reg.sort_values(by = 'rank_test_score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egzg2oBV11i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb = XGBClassifier(max_depth= 5, learning_rate=0.2, gamma= 5, subsample= 0.7, objective= 'reg:logistic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yklAgfLO6sTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRHjnDL96wom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XGB_y_pred = xgb.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QdNiy2mfFeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cofusion matrix\n",
        "XGB_confusion_mat = confusion_matrix(y_test, XGB_y_pred)\n",
        "XGB_confusion_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z-POYK4fRZD",
        "colab_type": "text"
      },
      "source": [
        "# STACKING "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Ywkz5gfrwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stacking():\n",
        "  level0 = list()\n",
        "  level0.append(('lr', LogisticRegression(C= 6, solver= 'saga' , penalty='l1') ))\n",
        "  level0.append(('xgb1', XGBClassifier(max_depth= 6, learning_rate=0.2, gamma= 7, subsample= 0.7, objective='reg:logistic') ))\n",
        "  level1 = LogisticRegression(C= 6, solver= 'saga', penalty = 'l1')\n",
        "  model = StackingClassifier(estimators=level0, final_estimator= level1, cv = 5)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbyrRWi4r4l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = get_stacking()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nZVvA7U5nfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjKUnii759c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacking_y_pred = models.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7qPzHJ9gAea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacking_confusion_mat = confusion_matrix(y_test, stacking_y_pred)\n",
        "stacking_confusion_mat"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}